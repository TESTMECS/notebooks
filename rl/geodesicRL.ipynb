{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpacetimeEmbedder(nn.Module):\n",
    "    def __init__(self, input_dim=4, hidden_dim=128, num_coupling_layers=6):\n",
    "        super().__init__()\n",
    "        self.inn_phi = INNPhi(input_dim, hidden_dim, num_coupling_layers)\n",
    "\n",
    "    def forward(self, x, reverse=False):\n",
    "        return self.inn_phi(x, reverse=reverse)\n",
    "\n",
    "    def pullback_metric(self, x):\n",
    "        return pullback_metric(x, self.inn_phi, eta_E=torch.diag(torch.tensor([-1.0, 1.0, 1.0, 1.0])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeodesicPolicy(nn.Module):\n",
    "    def __init__(self, state_dim, goal_dim, hidden_dim=256):\n",
    "        super().__init__()\n",
    "        self.subgoal_net = nn.Sequential(\n",
    "            nn.Linear(state_dim + goal_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, state_dim)\n",
    "        )\n",
    "        self.action_net = nn.Sequential(\n",
    "            nn.Linear(state_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, state_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, state, goal):\n",
    "        subgoal = self.subgoal_net(torch.cat([state, goal], dim=-1))\n",
    "        action = self.action_net(torch.cat([state, subgoal], dim=-1))\n",
    "        return action, subgoal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionODE(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim=256):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim + 1, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, t, a):\n",
    "        t_vec = t.expand(a.size(0), 1)\n",
    "        return self.net(torch.cat([a, t_vec], dim=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geodesic_loss(child, parent, margin=0.001, epsilon=1e-5):\n",
    "    dt = child[:, 0] - parent[:, 0]\n",
    "    dx2 = ((child[:, 1:] - parent[:, 1:]) ** 2).sum(dim=1)\n",
    "    interval_sq = -(dt ** 2) + dx2\n",
    "\n",
    "    causal_violation = torch.clamp(margin - dt, min=0) ** 2\n",
    "    interval_violation = (interval_sq + epsilon).pow(2)\n",
    "    return causal_violation.mean(), interval_violation.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeodesicRLTrainer:\n",
    "    def __init__(self, embedder, policy, ode_func, optimizer, gamma=0.99):\n",
    "        self.embedder = embedder\n",
    "        self.policy = policy\n",
    "        self.ode_func = ode_func\n",
    "        self.optimizer = optimizer\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def train_step(self, batch):\n",
    "        state, goal = batch[\"state\"], batch[\"goal\"]\n",
    "        e_state = self.embedder(state)\n",
    "        e_goal = self.embedder(goal)\n",
    "\n",
    "        # Policy prediction\n",
    "        action, subgoal = self.policy(e_state, e_goal)\n",
    "        evolved = odeint(self.ode_func, e_state, torch.tensor([0.0, 1.0]).to(state.device))[-1]\n",
    "\n",
    "        # Losses\n",
    "        causal_loss, interval_loss = geodesic_loss(evolved, e_goal)\n",
    "        imitation_loss = F.mse_loss(evolved, action.detach())\n",
    "        total_loss = imitation_loss + causal_loss + interval_loss\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return {\n",
    "            \"total_loss\": total_loss.item(),\n",
    "            \"causal_loss\": causal_loss.item(),\n",
    "            \"interval_loss\": interval_loss.item(),\n",
    "            \"imitation_loss\": imitation_loss.item()\n",
    "        }\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
